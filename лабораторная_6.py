# -*- coding: utf-8 -*-
"""Лабораторная 6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XlriBxPwDt-oWpn4mLwsu_u18_hy3ggx
"""

import matplotlib.pyplot as plt

celsius = [[-67.0], [-34.0], [0], [34.0], [54.0], [67.0], [100]]
fahrenheit = [[-88.6], [-29.2], [32.0], [93.2], [129.2], [152.6], [212.0],]

plt.figure(figsize=(15,8), dpi=50)
plt.scatter(celsius, fahrenheit, label='входные значения', color='green', marker='$f$')
plt.xlabel('celsius')
plt.ylabel('fahrenheit')
plt.legend()
plt.grid(True)
plt.show

for c, f in zip(celsius, fahrenheit):
  print(f'цельсия{c} = фаренгейта{f}')

from sklearn.linear_model import LinearRegression
lr = LinearRegression()
lr.fit(celsius, fahrenheit)
lr.predict([[256], [123]])
lr.coef_
lr.intercept_
celsius_test = [[-50], [10], [30], [20], [10], [70], [87]]
fahrenheit_test = lr.predict(celsius_test)
fahrenheit_test

for c, f in zip(celsius_test, fahrenheit_test):
  print(f'цельсия{c} фаренгейта{f}')

import numpy as np

x_range = np.arange(-70, 120)
y_range = x_range * 1.8 + 32

plt.figure(figsize=(15,8), dpi=280)
plt.plot(x_range, y_range, label='уравнение', linewidth='1')
plt.scatter(celsius, fahrenheit, label='входные данные', color='green')
plt.scatter(celsius_test, fahrenheit_test, label='предсказанное значение', color='blue')
plt.xlabel('Цельсия')
plt.ylabel('Фаренгейта')
plt.legend()
plt.grid(True)
plt.show()

# Самостоятельная работа

# Задания обычной сложности

#1

fahrenheit = [[-88.6], [-29.2], [32.0], [9.0], [100.0], [152.6], [212.0],]
kelvin = [[206.4833], [239.2611], [273.15], [260.372], [310.928], [339.81667], [373.15]]

plt.figure(figsize=(15,8), dpi=75)
plt.scatter(fahrenheit, kelvin, label='входные значения', color='green', marker='$f$')
plt.xlabel('fahrenheit')
plt.ylabel('kelvin')
plt.legend()
plt.grid(True)
plt.show

for f, k in zip(fahrenheit, kelvin):
  print(f'фаренгейта{f} = кельвин{k}')

from sklearn.linear_model import LinearRegression
lr = LinearRegression()
lr.fit(fahrenheit, kelvin)
lr.predict([[256], [123]])
lr.coef_
lr.intercept_
fahrenheit_test = [[-50], [10], [30], [20], [10], [70], [87]]
kelvin_test = lr.predict(celsius_test)
kelvin_test

for f, k in zip(fahrenheit_test, kelvin_test):
  print(f'фаренгейта{f} кельвин{k}')

x_range = np.arange(-100, 250)
y_range = (x_range -32) * 0.55 + 273.15

plt.figure(figsize=(15,8), dpi=280)
plt.plot(x_range, y_range, label='уравнение', linewidth='1')
plt.scatter(fahrenheit, kelvin, label='входные данные', color='green')
plt.scatter(fahrenheit_test, kelvin_test, label='предсказанное значение', color='blue')
plt.xlabel('Фаренгейта')
plt.ylabel('Кельвин')
plt.legend()
plt.grid(True)
plt.show()

#2

!git clone https://github.com/Proferister/Gorenskiy-Matvey-Maksimovich-PI-311

#3

# 1) Взаимная спектральная плотность (CSD)

import matplotlib.pyplot as plt
import numpy as np

fig, (ax1, ax2) = plt.subplots(2, 1, layout='constrained')

dt = 0.01
t = np.arange(0, 30, dt)

# Fixing random state for reproducibility
np.random.seed(19680801)


nse1 = np.random.randn(len(t))                 # white noise 1
nse2 = np.random.randn(len(t))                 # white noise 2
r = np.exp(-t / 0.05)

cnse1 = np.convolve(nse1, r, mode='same') * dt   # colored noise 1
cnse2 = np.convolve(nse2, r, mode='same') * dt   # colored noise 2

# two signals with a coherent part and a random part
s1 = 0.01 * np.sin(2 * np.pi * 10 * t) + cnse1
s2 = 0.01 * np.sin(2 * np.pi * 10 * t) + cnse2

ax1.plot(t, s1, t, s2)
ax1.set_xlim(0, 5)
ax1.set_xlabel('Time (s)')
ax1.set_ylabel('s1 and s2')
ax1.grid(True)

cxy, f = ax2.csd(s1, s2, 256, 1. / dt)
ax2.set_ylabel('CSD (dB)')

plt.show()

# 2) Сгруппированная столбчатая диаграмма с метками

import matplotlib.pyplot as plt
import numpy as np

species = ("Adelie", "Chinstrap", "Gentoo")
penguin_means = {
    'Bill Depth': (18.35, 18.43, 14.98),
    'Bill Length': (38.79, 48.83, 47.50),
    'Flipper Length': (189.95, 195.82, 217.19),
}

x = np.arange(len(species))  # the label locations
width = 0.25  # the width of the bars
multiplier = 0

fig, ax = plt.subplots(layout='constrained')

for attribute, measurement in penguin_means.items():
    offset = width * multiplier
    rects = ax.bar(x + offset, measurement, width, label=attribute)
    ax.bar_label(rects, padding=3)
    multiplier += 1

# Add some text for labels, title and custom x-axis tick labels, etc.
ax.set_ylabel('Length (mm)')
ax.set_title('Penguin attributes by species')
ax.set_xticks(x + width, species)
ax.legend(loc='upper left', ncols=3)
ax.set_ylim(0, 250)

plt.show()

# 3) Анимация pyplot

import matplotlib.pyplot as plt
import numpy as np

np.random.seed(19680801)
data = np.random.random((50, 50, 50))

fig, ax = plt.subplots()

for i, img in enumerate(data):
    ax.clear()
    ax.imshow(img)
    ax.set_title(f"frame {i}")
    # Note that using time.sleep does *not* work here!
    plt.pause(0.1)

# 4

import math

# функция для вычисления факториала:

def factorial(n):
  f = 1
  for i in range(2, n + 1):
    f *= i
  return f

# функция для вычисления НОД:

def NOD(m, n):

  if m > n:
    a, b = m, n
  else:
    a, b = n, m

  while b != 0:

    r = a % b
    a, b = b, r

  NOD = a
  print('НОД(%d, %d) = %d' % (m, n, NOD))

print(f'Число Эйлера: {math.e}')
print(f'Число Пи: {math.pi}')
print(f'nan: {math.nan}')
print(f'Число Эйлера: {math.e}')
factorial(2) # факториал из числа, которое является моим порядковым номером в журнале
NOD(2, 128) # НОД для числа, которое является моим порядковым номером в журнале и для числа, которое обозначет количество памяти в моём телефоне

# Задания повышенной сложности

# 1

import matplotlib.pyplot as plt
import numpy as np

radius = 1

u, v = np.mgrid [0: 2*np.pi: 20j, 0: np.pi: 10j]

x = radius * np.cos (u) * np.sin (v)
y = radius * np.sin (u) * np.sin (v)
z = radius * np.cos (v)

fig = plt.figure ()
ax = fig.add_subplot (projection = '3d')

ax.plot_surface (x, y, z, color = 'blue')

ax.set_xlabel ('x')
ax.set_ylabel ('y')
ax.set_zlabel ('z')

ax.set_title ('nariui sphere')

plt.show ()

# Commented out IPython magic to ensure Python compatibility.
# 2

# numpy используется для поддержки многомерных массивов, поддержки высокоуровневых математических функций, предназначенных для работы с многомерными массивами.
# matlotlib используется для визуализации данных двумерной и трёхмерной графики.
# tensorflow используется для решения задач построения и тренировки нейронной сети.
# keras обеспечивает взаимодействие с искусственными нейронными сетями.
# fashion mnist - это большая свободно доступная база данных изображений моды, которая обычно используется для обучения и тестирования различных систем машинного обучения.
# Sequential - это класс последовательной модели, представляет из себя 3-х слойную структуру: входной слой, скрытый слой, выходной слой.
# Dense используется для реализации входного слоя
# Dropout используется для реализации выходного слоя
# Utils этот пакет предоставляет утилиты для Keras, такие как модифицированные обратные вызовы, генераторы и т.д.

import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
# %matplotlib inline
from tensorflow.keras.datasets import fashion_mnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras import utils

# Делим наш датасет на обучающую и тестовую выборку

(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()

# Добавляем имена классов

class_names = ['T-shirt/top',
               'Trouser',
               'Pullover',
               'Dress',
               'Coat',
               'Sandal',
               'Shirt',
               'Sneaker',
               'Bag',
               'Ankle boot']

# Предварительная обработка данных

# Посмотрим, как выглядит изображение

plt.figure()
plt.imshow(x_train[0])
plt.colorbar()
plt.grid(False)

# Нормализация данных

# делим интенсивность изображения на 255

x_train = x_train / 255
x_test = x_test / 255

# Проверка

plt.figure()
plt.imshow(x_train[0])
plt.colorbar()
plt.grid(False)

# Теперь интенсивность пикселей варьируется от 0 до 1

# Посмотрим несколько изображений

plt.figure(figsize=(10,10))
for i in range(25):
  plt.subplot(5,5,i+1)
  plt.xticks([])
  plt.yticks([])
  plt.imshow(x_train[i])
  plt.xlabel(class_names[y_train[i]])

# Создание модели нейронной сети

model = keras.Sequential([
    keras.layers.Flatten(input_shape=(28,28)),
    keras.layers.Dense(128, activation='relu'),
    keras.layers.Dense(10, activation='softmax')
])

# Компиляция модели

model.compile(optimizer=tf.keras.optimizers.SGD(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Выведем на экран параметры нашей модели

model.summary()

# Обучение модели

model.fit(x_train, y_train, epochs=10)

# Проверка точности предсказания

test_loss, test_acc = model.evaluate(x_test, y_test)
print('Test accuracy: ', test_acc)

# Попытки предсказания

predictions = model.predict(x_train)

predictions[0]

np.argmax(predictions[0])

y_train[0]

plt.figure()
plt.imshow(x_train[0])
plt.colorbar()
plt.grid(False)

class_names[np.argmax(predictions[0])]

# Другая версия кода

import tensorflow as tf

import numpy as np
import matplotlib.pyplot as plt

# Load the fashion-mnist pre-shuffled train data and test data
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()

print("x_train shape:", x_train.shape, "y_train shape:", y_train.shape)

# Print training set shape - note there are 60,000 training data of image size of 28x28, 60,000 train labels)
print("x_train shape:", x_train.shape, "y_train shape:", y_train.shape)

# Print the number of training and test datasets
print(x_train.shape[0], 'train set')
print(x_test.shape[0], 'test set')

# Define the text labels
fashion_mnist_labels = ["T-shirt/top",  # index 0
                        "Trouser",      # index 1
                        "Pullover",     # index 2
                        "Dress",        # index 3
                        "Coat",         # index 4
                        "Sandal",       # index 5
                        "Shirt",        # index 6
                        "Sneaker",      # index 7
                        "Bag",          # index 8
                        "Ankle boot"]   # index 9

# Image index, you can pick any number between 0 and 59,999
img_index = 5
# y_train contains the lables, ranging from 0 to 9
label_index = y_train[img_index]
# Print the label, for example 2 Pullover
print ("y = " + str(label_index) + " " +(fashion_mnist_labels[label_index]))
# # Show one of the images from the training dataset
plt.imshow(x_train[img_index])

x_train = x_train.astype('float32') / 255
x_test = x_test.astype('float32') / 255

print("Number of train data - " + str(len(x_train)))
print("Number of test data - " + str(len(x_test)))

# Further break training data into train / validation sets (# put 5000 into validation set and keep remaining 55,000 for train)
(x_train, x_valid) = x_train[5000:], x_train[:5000]
(y_train, y_valid) = y_train[5000:], y_train[:5000]

# Reshape input data from (28, 28) to (28, 28, 1)
w, h = 28, 28
x_train = x_train.reshape(x_train.shape[0], w, h, 1)
x_valid = x_valid.reshape(x_valid.shape[0], w, h, 1)
x_test = x_test.reshape(x_test.shape[0], w, h, 1)

# One-hot encode the labels
y_train = tf.keras.utils.to_categorical(y_train, 10)
y_valid = tf.keras.utils.to_categorical(y_valid, 10)
y_test = tf.keras.utils.to_categorical(y_test, 10)

# Print training set shape
print("x_train shape:", x_train.shape, "y_train shape:", y_train.shape)

# Print the number of training, validation, and test datasets
print(x_train.shape[0], 'train set')
print(x_valid.shape[0], 'validation set')
print(x_test.shape[0], 'test set')

model = tf.keras.Sequential()

# Must define the input shape in the first layer of the neural network
model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1)))
model.add(tf.keras.layers.MaxPooling2D(pool_size=2))
model.add(tf.keras.layers.Dropout(0.3))

model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))
model.add(tf.keras.layers.MaxPooling2D(pool_size=2))
model.add(tf.keras.layers.Dropout(0.3))

model.add(tf.keras.layers.Flatten())
model.add(tf.keras.layers.Dense(256, activation='relu'))
model.add(tf.keras.layers.Dropout(0.5))
model.add(tf.keras.layers.Dense(10, activation='softmax'))

# Take a look at the model summary
model.summary()

model.compile(loss='categorical_crossentropy',
             optimizer='adam',
             metrics=['accuracy'])

from keras.callbacks import ModelCheckpoint

checkpointer = ModelCheckpoint(filepath='model.weights.best.keras', verbose = 1, save_best_only=True)
model.fit(x_train,
         y_train,
         batch_size=64,
         epochs=10,
         validation_data=(x_valid, y_valid),
         callbacks=[checkpointer])

# Load the weights with the best validation accuracy
model.load_weights('model.weights.best.keras')

# Evaluate the model on test set
score = model.evaluate(x_test, y_test, verbose=0)

# Print test accuracy
print('\n', 'Test accuracy:', score[1])

y_hat = model.predict(x_test)

# Plot a random sample of 10 test images, their predicted labels and ground truth
figure = plt.figure(figsize=(20, 8))
for i, index in enumerate(np.random.choice(x_test.shape[0], size=15, replace=False)):
    ax = figure.add_subplot(3, 5, i + 1, xticks=[], yticks=[])
    # Display each image
    ax.imshow(np.squeeze(x_test[index]))
    predict_index = np.argmax(y_hat[index])
    true_index = np.argmax(y_test[index])
    # Set the title for each image
    ax.set_title("{} ({})".format(fashion_mnist_labels[predict_index],
                                  fashion_mnist_labels[true_index]),
                                  color=("green" if predict_index == true_index else "red"))